{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import statsmodels.api as sm\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "from ISLP import confusion_table\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"../data/card_transdata.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "# Visualize the correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.hist(bins=20, figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fraud']\n",
    "X = MS(['distance_from_home','distance_from_last_transaction','ratio_to_median_purchase_price','repeat_retailer','used_chip','used_pin_number','online_order']).fit_transform(df) \n",
    "#X = df.drop('fraud', axis='columns')\n",
    "#X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X)\n",
    "results1 = model1.fit()\n",
    "summarize(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression\n",
    "model = sm.OLS.from_formula('fraud ~ distance_from_home * distance_from_last_transaction', data=df)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression with variable interactions\n",
    "model = sm.OLS.from_formula('fraud ~ distance_from_last_transaction * ratio_to_median_purchase_price* distance_from_home* used_chip', data=df)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try the KNN model\n",
    "# Select predictors (excluding the last column)\n",
    "predictors = df.iloc[:, :-1]\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head())\n",
    "# Create a random vector of True and False values\n",
    "np.random.seed(4)\n",
    "split = np.random.choice([True, False], size=len(predictors_standardized), replace=True, p=[0.75, 0.25])\n",
    "\n",
    "# Define the training set for X (predictors)\n",
    "training_X = predictors_standardized[split]\n",
    "\n",
    "# Define the training set for Y (response)\n",
    "training_Y = df.loc[split, 'fraud']\n",
    "\n",
    "# Define the testing set for X (predictors)\n",
    "testing_X = predictors_standardized[~split]\n",
    "\n",
    "# Define the testing set for Y (response)\n",
    "testing_Y = df.loc[~split, 'fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors =3)\n",
    "knn_fit=knn.fit(training_X,training_Y)\n",
    "knn_pred = knn.predict(testing_X)\n",
    "confusion_table(knn_pred,testing_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy = knn.score(testing_X,testing_Y)\n",
    "print(prediction_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is highly imbalanced\n",
    "df.fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liz: Trying random undersampling, reducing the samples of non-fraud to match that of fraud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#Separate majority, minority class\n",
    "df_majority = df[df['fraud']==0.0]\n",
    "df_minority = df[df['fraud']==1.0]\n",
    "\n",
    "#downsample majority \"non-fraud\" class\n",
    "df_majority_downsampled = resample(df_majority, replace= False, n_samples=len(df_minority), random_state=42)\n",
    "\n",
    "#combine downsampled majority + minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "#separate predictors (x) and target variable (y)\n",
    "X_downsampled = df_downsampled.drop('fraud', axis=1)\n",
    "y_downsampled = df_downsampled['fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the downsampled dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_downsampled, y_downsampled, test_size=0.25, random_state=42)\n",
    "\n",
    "#train a random forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even after random undersampling, the accuracy still seems high at 99.99%.\n",
    "#Let's check the class distribution after undersampling\n",
    "\n",
    "print(\"Class distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Class distribution in testing set\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC AUC score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Comparing with the original dataset KNN results, the original dataset has an accuracy of 99.87% while the undersampled dataset has an accuracy of 99.99%\n",
    "#There might be an issue of potential overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
